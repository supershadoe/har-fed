{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51359756-cba2-4251-ae6c-c96d7af3065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc320a0-3b6d-4829-9b31-68839bd6e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_activity_map():\n",
    "    map = {}\n",
    "    map[0] = 'transient'\n",
    "    map[1] = 'lying'\n",
    "    map[2] = 'sitting'\n",
    "    map[3] = 'standing'\n",
    "    map[4] = 'walking'\n",
    "    map[5] = 'running'\n",
    "    map[6] = 'cycling'\n",
    "    map[7] = 'Nordic_walking'\n",
    "    map[9] = 'watching_TV'\n",
    "    map[10] = 'computer_work'\n",
    "    map[11] = 'car driving'\n",
    "    map[12] = 'ascending_stairs'\n",
    "    map[13] = 'descending_stairs'\n",
    "    map[16] = 'vacuum_cleaning'\n",
    "    map[17] = 'ironing'\n",
    "    map[18] = 'folding_laundry'\n",
    "    map[19] = 'house_cleaning'\n",
    "    map[20] = 'playing_soccer'\n",
    "    map[24] = 'rope_jumping'\n",
    "    return map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383aa2fe-31be-451c-bbef-91f1106d8efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:59: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:59: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\G15\\AppData\\Local\\Temp\\ipykernel_10248\\24979378.py:59: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  subject = pd.read_table(path, header=None, sep='\\s+')\n"
     ]
    }
   ],
   "source": [
    "def generate_three_IMU(name):\n",
    "    x = name +'_x'\n",
    "    y = name +'_y'\n",
    "    z = name +'_z'\n",
    "    return [x,y,z]\n",
    "\n",
    "def generate_four_IMU(name):\n",
    "    x = name +'_x'\n",
    "    y = name +'_y'\n",
    "    z = name +'_z'\n",
    "    w = name +'_w'\n",
    "    return [x,y,z,w]\n",
    "\n",
    "def generate_cols_IMU(name):\n",
    "    # temp\n",
    "    temp = name+'_temperature'\n",
    "    output = [temp]\n",
    "    # acceleration 16\n",
    "    acceleration16 = name+'_3D_acceleration_16'\n",
    "    acceleration16 = generate_three_IMU(acceleration16)\n",
    "    output.extend(acceleration16)\n",
    "    # acceleration 6\n",
    "    acceleration6 = name+'_3D_acceleration_6'\n",
    "    acceleration6 = generate_three_IMU(acceleration6)\n",
    "    output.extend(acceleration6)\n",
    "    # gyroscope\n",
    "    gyroscope = name+'_3D_gyroscope'\n",
    "    gyroscope = generate_three_IMU(gyroscope)\n",
    "    output.extend(gyroscope)\n",
    "    # magnometer\n",
    "    magnometer = name+'_3D_magnetometer'\n",
    "    magnometer = generate_three_IMU(magnometer)\n",
    "    output.extend(magnometer)\n",
    "    # oreintation\n",
    "    oreintation = name+'_4D_orientation'\n",
    "    oreintation = generate_four_IMU(oreintation)\n",
    "    output.extend(oreintation)\n",
    "    return output\n",
    "\n",
    "def load_IMU():\n",
    "    output = ['time_stamp','activity_id', 'heart_rate']\n",
    "    hand = 'hand'\n",
    "    hand = generate_cols_IMU(hand)\n",
    "    output.extend(hand)\n",
    "    chest = 'chest'\n",
    "    chest = generate_cols_IMU(chest)\n",
    "    output.extend(chest)\n",
    "    ankle = 'ankle'\n",
    "    ankle = generate_cols_IMU(ankle)\n",
    "    output.extend(ankle)\n",
    "    return output\n",
    "    \n",
    "def load_subjects(root='../PAMAP2_Dataset/subject'):\n",
    "    output = pd.DataFrame()\n",
    "    cols = load_IMU()\n",
    "    \n",
    "    for i in range(101,110):\n",
    "        path = root + str(i) +'.dat'\n",
    "        subject = pd.read_table(path, header=None, sep='\\s+')\n",
    "        subject.columns = cols \n",
    "        subject['id'] = i\n",
    "        output = pd.concat([output,subject],ignore_index = True)\n",
    "    output.reset_index(drop=True, inplace=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c6d75c2-2266-427f-8c51-ded855a8b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_data(data):\n",
    "    data = data.drop(data[data['activity_id']==0].index)\n",
    "    data = data.interpolate()\n",
    "    # fill all the NaN values in a coulmn with the mean values of the column\n",
    "    for colName in data.columns:\n",
    "        data[colName] = data[colName].fillna(data[colName].mean())\n",
    "    activity_mean = data.groupby(['activity_id']).mean().reset_index()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c0d192-a117-4177-80e9-b1be844e7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fix_data(load_subjects())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae9e6c53-5693-44ed-b6b9-d183f3bb5d92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m new_data = \u001b[43mdata\u001b[49m.copy().reset_index()\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# new_data = new_data.drop('index',axis=1)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# new_data = new_data.reset_index()\u001b[39;00m\n\u001b[32m      4\u001b[39m new_cols = \u001b[38;5;28;01mNone\u001b[39;00m \n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "new_data = data.copy().reset_index()\n",
    "# new_data = new_data.drop('index',axis=1)\n",
    "# new_data = new_data.reset_index()\n",
    "new_cols = None \n",
    "for subject in range(101,110):\n",
    "    prev_act_1 = new_data[new_data['id'] == subject]\n",
    "    start = prev_act_1.head(2).index[1]\n",
    "    end = prev_act_1.tail(1).index[0]\n",
    "    prev_act_1 = prev_act_1.loc[start:end+1]\n",
    "    new_cols_1 = pd.DataFrame()\n",
    "    new_cols_1['prev_aid'] = prev_act_1['activity_id']\n",
    "    new_cols_1['prev_hr'] = prev_act_1['heart_rate']\n",
    "    new_cols_1['index'] = prev_act_1['index'] + 1\n",
    "    if new_cols is None:\n",
    "        new_cols = new_cols_1\n",
    "    else:\n",
    "        new_cols = pd.concat([new_cols,new_cols_1])\n",
    "new_cols = new_data.merge(new_cols, on='index', how='left')\n",
    "new_cols = new_cols.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90262a44-3526-4fa8-a7d0-47d1fa658694",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test(new_cols)\n",
    "print('Train shape X :',X_train.shape,' y ', y_train.shape)\n",
    "print('Test shape X :',X_test.shape,' y ', y_test.shape)\n",
    "\n",
    "X_lstm_train, y_lstm_train = create_lstm_data(X_train, y_train)\n",
    "X_lstm_test, y_lstm_test = create_lstm_data(X_test, y_test)\n",
    "hot = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "hot.fit(y_lstm_train)\n",
    "hot.fit(y_lstm_test)a\n",
    "\n",
    "y_lstm_train = hot.transform(y_lstm_train)\n",
    "y_lstm_test = hot.transform(y_lstm_test)\n",
    "print('Train shape X lstm :',X_lstm_train.shape,' y ', y_lstm_train.shape)\n",
    "print('Test shape X lstm :',X_lstm_test.shape,' y ', y_lstm_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3a8a9b-a883-480a-b8cd-eaff31e7cbc2",
   "metadata": {},
   "source": [
    "MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d51263-aec2-4d45-815c-7f4510c9a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(16,input_shape=(X_lstm_train.shape[1],X_lstm_train.shape[2])))\n",
    "lstm_model.add(Dense(64 ,activation='relu'))\n",
    "lstm_model.add(Dense(64 ,activation='relu'))\n",
    "lstm_model.add(Dropout(0.1))\n",
    "lstm_model.add(Dense(64 ,activation='relu'))\n",
    "lstm_model.add(Dense(64 ,activation='relu'))\n",
    "lstm_model.add(Dense(y_lstm_train.shape[1], activation='softmax'))\n",
    "\n",
    "lstm_model.summary()\n",
    "lstm_model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc60edf3-c751-4c9f-bf21-a06c726f136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "history = lstm_model.fit(X_lstm_train, y_lstm_train, validation_split = 0.2 , epochs = 10, callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b523e44-03ad-4fc6-b5f1-76f924167cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_plot_history(history):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "quick_plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d845dc-28ce-48ab-ada0-6d8342a5b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_test[5:-1]\n",
    "preds = lstm_model.predict(X_lstm_test)\n",
    "preds_cat = np.argmax(preds,axis=1)\n",
    "# building a map of result to activity\n",
    "result = np.unique(preds_cat).tolist() \n",
    "expected = np.unique(y).tolist() \n",
    "combined = list(zip(result,expected))\n",
    "conf_map = dict(combined)\n",
    "# transfoms the prediction to an activity\n",
    "results = [conf_map[x] for x in preds_cat]\n",
    "print('model accuracy on test :',accuracy_score(y,results)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
